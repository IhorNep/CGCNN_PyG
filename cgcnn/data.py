from __future__ import print_function, division

import csv
import functools
import json
import os
import random
import warnings

import numpy as np
import pandas as pd
import torch
from pymatgen.core.structure import Structure
from pymatgen.analysis.bond_valence import BVAnalyzer
from torch.utils.data import Dataset
from torch_geometric.data import DataLoader, Data
from torch.utils.data.dataloader import default_collate
from torch.utils.data.sampler import SubsetRandomSampler
from matminer.datasets import load_dataset
from xenonpy.datatools import preset
from tqdm import trange
from statistics import mean, stdev

def get_train_val_test_loader(dataset, collate_fn=default_collate,
                              batch_size=64, train_ratio=None,
                              val_ratio=0.1, test_ratio=0.1, return_test=False,
                              num_workers=1, pin_memory=False, **kwargs):

    total_size = len(dataset)
    if train_ratio is None:
        assert val_ratio + test_ratio < 1
        train_ratio = 1 - val_ratio - test_ratio
        print('[Warning] train_ratio is None, using all training data.')
    else:
        assert train_ratio + val_ratio + test_ratio <= 1
    indices = list(range(total_size))
    if kwargs['train_size']:
        train_size = kwargs['train_size']
    else:
        train_size = int(train_ratio * total_size)
    if kwargs['test_size']:
        test_size = kwargs['test_size']
    else:
        test_size = int(test_ratio * total_size)
    if kwargs['val_size']:
        valid_size = kwargs['val_size']
    else:
        valid_size = int(val_ratio * total_size)
    np.random.seed(123)
    torch.manual_seed(123)
    train_sampler = SubsetRandomSampler(indices[:train_size])
    val_sampler = SubsetRandomSampler(
        indices[-(valid_size + test_size):-test_size])
    if return_test:
        test_sampler = SubsetRandomSampler(indices[-test_size:])
    train_loader = DataLoader(dataset, batch_size=batch_size,
                              sampler=train_sampler,
                              num_workers=num_workers,
                              pin_memory=pin_memory)
    val_loader = DataLoader(dataset, batch_size=batch_size,
                            sampler=val_sampler,
                            num_workers=num_workers,
                            pin_memory=pin_memory)
    if return_test:
        test_loader = DataLoader(dataset, batch_size=batch_size,
                                 sampler=test_sampler,
                                 num_workers=num_workers,
                                 pin_memory=pin_memory)
    if return_test:
        return train_loader, val_loader, test_loader
    else:
        return train_loader, val_loader


class GaussianDistance(object):
    """
    Expands the distance by Gaussian basis.

    Unit: angstrom
    """
    def __init__(self, dmin, dmax, step, var=None):
        """
        Parameters
        ----------

        dmin: float
          Minimum interatomic distance
        dmax: float
          Maximum interatomic distance
        step: float
          Step size for the Gaussian filter
        """
        assert dmin < dmax
        assert dmax - dmin > step
        self.filter = np.arange(dmin, dmax+step, step)
        if var is None:
            var = step
        self.var = var

    def expand(self, distances):
        """
        Apply Gaussian disntance filter to a numpy distance array

        Parameters
        ----------

        distance: np.array shape n-d array
          A distance matrix of any shape

        Returns
        -------
        expanded_distance: shape (n+1)-d array
          Expanded distance matrix with the last dimension of length
          len(self.filter)
        """
        if orbital_ == True:
            return distances[..., np.newaxis]
        else:
            return np.exp(-(distances[..., np.newaxis] - self.filter)**2 /
                          self.var**2)



class AtomInitializer(object):
    """
    Base class for intializing the vector representation for atoms.

    !!! Use one AtomInitializer per dataset !!!
    """
    def __init__(self, atom_types):
        self.atom_types = set(atom_types)
        self._embedding = {}

    def get_atom_fea(self, atom_type, cif_id):
        assert atom_type in self.atom_types
        return self._embedding[atom_type]

    def load_state_dict(self, state_dict):
        self._embedding = state_dict
        self.atom_types = set(self._embedding.keys())
        self._decodedict = {idx: atom_type for atom_type, idx in
                            self._embedding.items()}

    def state_dict(self):
        return self._embedding

    def decode(self, idx):
        if not hasattr(self, '_decodedict'):
            self._decodedict = {idx: atom_type for atom_type, idx in
                                self._embedding.items()}
        return self._decodedict[idx]


class AtomCustomJSONInitializer(AtomInitializer):
    """
    Initialize atom feature vectors using a JSON file, which is a python
    dictionary mapping from element number to a list representing the
    feature vector of the element.

    Parameters
    ----------

    elem_embedding_file: str
        The path to the .json file
    """
    def __init__(self, elem_embedding_file):
        with open(elem_embedding_file) as f:
            elem_embedding = json.load(f)
        elem_embedding = {int(key): value for key, value
                          in elem_embedding.items()}
        atom_types = set(elem_embedding.keys())
        super(AtomCustomJSONInitializer, self).__init__(atom_types)
        for key, value in elem_embedding.items():
            self._embedding[key] = np.array(value, dtype=float)

class CIFData(Dataset):

    def __init__(self, root_dir=None, max_num_nbr=12, radius=8, dmin=0, step=0.2,
                 random_seed=123, matminer_dataset=None, MP_target=None, orbital = False):
        global orbital_
        orbital_ = orbital
        self.root_dir = root_dir
        self.max_num_nbr, self.radius = max_num_nbr, radius
        assert os.path.exists(root_dir), 'root_dir does not exist!'
        id_prop_file = os.path.join(self.root_dir, 'id_prop.csv')

        id_prop_file = os.path.join(self.root_dir, 'id_prop.csv')
        assert os.path.exists(id_prop_file), 'id_prop.csv does not exist!'

        with open(id_prop_file) as f:
            reader = csv.reader(f)
            self.id_prop_data = [row for row in reader]
        random.seed(random_seed)
        random.shuffle(self.id_prop_data)
        if orbital == True:
            atom_init_file = os.path.join(self.root_dir, 'atom_init_orbital.json')
            assert os.path.exists(atom_init_file), 'atom_init_orbital.json does not exist!'
        else:
            atom_init_file = os.path.join(self.root_dir, 'atom_init.json')
            assert os.path.exists(atom_init_file), 'atom_init.json does not exist!'
        self.ari = AtomCustomJSONInitializer(atom_init_file)
        self.gdf = GaussianDistance(dmin=dmin, dmax=self.radius, step=step)

    def __len__(self):
        length = len(self.id_prop_data)
        return length

    @functools.lru_cache(maxsize=None)  # Cache loaded structures
    def __getitem__(self, idx):
        cif_id, target = self.id_prop_data[idx]

        crystal = Structure.from_file(os.path.join(self.root_dir,
                                                cif_id+'.cif'))



        all_nbrs = crystal.get_all_neighbors(self.radius, include_index=True)

        all_nbrs = [sorted(nbrs, key=lambda x: x[1]) for nbrs in all_nbrs]
        bond_index = [[],[]]
        bond_attr = []
        for i, nbrs in enumerate(all_nbrs):
            if len(nbrs) < self.max_num_nbr:
                warnings.warn('{} not find enough neighbors to build graph. '
                              'If it happens frequently, consider increase '
                              'radius.'.format(cif_id))
            else:
                bond_index[0] += [i]*self.max_num_nbr
                bond_index[1].extend(list(map(lambda x: x[2], nbrs[:self.max_num_nbr])))
                if orbital_ == True:
                    bond_attr.extend(list(map(lambda x: (x[1] - 2.8719234)/0.7001912, nbrs[:self.max_num_nbr])))
                else:
                    bond_attr.extend(list(map(lambda x: x[1], nbrs[:self.max_num_nbr])))

        atom_fea = np.vstack([self.ari.get_atom_fea(crystal[i].specie.number, cif_id)
                              for i in range(len(crystal))])

        atom_fea = torch.Tensor(atom_fea)
        bond_index, bond_attr = np.array(bond_index), np.array(bond_attr)
        bond_attr = self.gdf.expand(bond_attr)
        bond_attr = torch.Tensor(bond_attr)
        bond_index = torch.LongTensor(bond_index)
        target = torch.Tensor([float(target)])

        return Data(x = atom_fea, edge_index = bond_index,
                    edge_attr = bond_attr, y = target, cif_id = cif_id)
